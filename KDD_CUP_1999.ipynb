{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "df402be3",
      "metadata": {
        "id": "df402be3"
      },
      "source": [
        "\n",
        "# KDD Cup 1999 - Anomali Tespiti\n",
        "\n",
        "Bu defter, KDD Cup 1999 veri seti üzerinde **anomali (saldırı) tespiti** için uçtan uca bir akış sunar:\n",
        "1. **Veri Yükleme** (CSV)\n",
        "2. **Ön İşleme** (One-Hot + Standardizasyon, Train/Test)\n",
        "3. **Modeller**: Lojistik Regresyon, Random Forest, Decision Tree, Lineer (SGDClassifier), *(opsiyonel)* XGBoost\n",
        "4. **Hiperparametre Optimizasyonu** (GridSearchCV)\n",
        "5. **Değerlendirme** (ROC-AUC, PR-Eğrisi, F1, Confusion Matrix)\n",
        "6. **PCA(2)** üzerinde **karar sınırı** görselleştirme (SVM ile)\n",
        "7. **K-Means**: Elbow (WCSS) + **Silhouette** skoru\n",
        "8. **SelectKBest (ANOVA F)** ile örnek **özellik seçimi**\n",
        "\n",
        "> Bu çalışma **sınıflandırma** problemidir (Normal vs Attack).\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "8836d859",
      "metadata": {
        "id": "8836d859"
      },
      "outputs": [],
      "source": [
        "\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.metrics import (\n",
        "    roc_auc_score, roc_curve, precision_recall_curve,\n",
        "    average_precision_score, f1_score, confusion_matrix,\n",
        "    classification_report\n",
        ")\n",
        "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "\n",
        "try:\n",
        "    from xgboost import XGBClassifier\n",
        "    XGB_AVAILABLE = True\n",
        "except Exception as e:\n",
        "    XGB_AVAILABLE = False\n",
        "    print(\"XGBoost bulunamadı. Kurmak için: pip install xgboost\")\n",
        "\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.metrics import silhouette_score\n",
        "from sklearn.feature_selection import SelectKBest, f_classif\n",
        "\n",
        "import joblib\n",
        "\n",
        "plt.rcParams['figure.figsize'] = (8, 6)\n",
        "RANDOM_STATE = 42\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c13aaeb4",
      "metadata": {
        "id": "c13aaeb4"
      },
      "source": [
        "\n",
        "## I. Veri Setinin Yüklenmesi\n",
        "\n",
        "Bu bölümde **KDD Cup 1999** veri seti `pandas` ile CSV'den okunur.  \n",
        "Etiket sütunu (`label`) **ikili** hale getirilir: `normal` → 0, diğer saldırılar → 1.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "c80b0aee",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 228
        },
        "id": "c80b0aee",
        "outputId": "4bd92946-4782-45e7-ea86-227a98e3acce"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "Veri dosyası bulunamadı: kdd99.csv\nCSV dosyasını klasöre koyup DATA_PATH'i güncelleyin.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3605795086.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDATA_PATH\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m     raise FileNotFoundError(\n\u001b[0m\u001b[1;32m     20\u001b[0m         \u001b[0;34mf\"Veri dosyası bulunamadı: {DATA_PATH}\\n\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0;34m\"CSV dosyasını klasöre koyup DATA_PATH'i güncelleyin.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: Veri dosyası bulunamadı: kdd99.csv\nCSV dosyasını klasöre koyup DATA_PATH'i güncelleyin."
          ]
        }
      ],
      "source": [
        "\n",
        "# CSV dosya yolu\n",
        "DATA_PATH = \"kdd99.csv\"\n",
        "\n",
        "# KDD 1999 özellik isimleri (41 + label)\n",
        "KDD_COLUMNS = [\n",
        "    \"duration\",\"protocol_type\",\"service\",\"flag\",\"src_bytes\",\"dst_bytes\",\"land\",\n",
        "    \"wrong_fragment\",\"urgent\",\"hot\",\"num_failed_logins\",\"logged_in\",\"num_compromised\",\n",
        "    \"root_shell\",\"su_attempted\",\"num_root\",\"num_file_creations\",\"num_shells\",\n",
        "    \"num_access_files\",\"num_outbound_cmds\",\"is_host_login\",\"is_guest_login\",\n",
        "    \"count\",\"srv_count\",\"serror_rate\",\"srv_serror_rate\",\"rerror_rate\",\"srv_rerror_rate\",\n",
        "    \"same_srv_rate\",\"diff_srv_rate\",\"srv_diff_host_rate\",\"dst_host_count\",\n",
        "    \"dst_host_srv_count\",\"dst_host_same_srv_rate\",\"dst_host_diff_srv_rate\",\n",
        "    \"dst_host_same_src_port_rate\",\"dst_host_srv_diff_host_rate\",\"dst_host_serror_rate\",\n",
        "    \"dst_host_srv_serror_rate\",\"dst_host_rerror_rate\",\"dst_host_srv_rerror_rate\",\n",
        "    \"label\"\n",
        "]\n",
        "\n",
        "if not os.path.exists(DATA_PATH):\n",
        "    raise FileNotFoundError(\n",
        "        f\"Veri dosyası bulunamadı: {DATA_PATH}\\n\"\n",
        "        \"CSV dosyasını klasöre koyup DATA_PATH'i güncelleyin.\"\n",
        "    )\n",
        "\n",
        "df = pd.read_csv(DATA_PATH, header=None, names=KDD_COLUMNS)\n",
        "\n",
        "# İkili hedef\n",
        "df['label_binary'] = np.where(df['label'].astype(str).str.contains('normal'), 0, 1)\n",
        "\n",
        "print(\"Veri şekli:\", df.shape)\n",
        "print(\"Saldırı oranı (1):\", round(df['label_binary'].mean(), 4))\n",
        "df.head()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "538f5262",
      "metadata": {
        "id": "538f5262"
      },
      "source": [
        "\n",
        "## II. Veri Ön İşleme\n",
        "\n",
        "- Kategorik: `protocol_type`, `service`, `flag` → **One-Hot Encoding**  \n",
        "- Sayısal: Diğer tüm sütunlar → **StandardScaler**  \n",
        "- **Stratified** train/test bölme (sınıf oranını korur)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a38d95fc",
      "metadata": {
        "id": "a38d95fc"
      },
      "outputs": [],
      "source": [
        "\n",
        "categorical_cols = ['protocol_type', 'service', 'flag']\n",
        "numeric_cols = [c for c in df.columns if c not in categorical_cols + ['label', 'label_binary']]\n",
        "\n",
        "X = df[categorical_cols + numeric_cols]\n",
        "y = df['label_binary']\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, stratify=y, random_state=RANDOM_STATE\n",
        ")\n",
        "\n",
        "preprocess = ColumnTransformer(\n",
        "    transformers=[\n",
        "        (\"cat\", OneHotEncoder(handle_unknown=\"ignore\"), categorical_cols),\n",
        "        (\"num\", StandardScaler(with_mean=False), numeric_cols)  # sparse uyumu\n",
        "    ]\n",
        ")\n",
        "\n",
        "# Dengesizlik için ölçek önerisi (XGBoost'ta kullanılacak)\n",
        "pos = (y_train == 1).sum()\n",
        "neg = (y_train == 0).sum()\n",
        "scale_pos_weight_val = float(neg) / float(pos) if pos > 0 else 1.0\n",
        "print(\"scale_pos_weight önerisi:\", round(scale_pos_weight_val, 2))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4ee3b212",
      "metadata": {
        "id": "4ee3b212"
      },
      "source": [
        "\n",
        "## III. Modeller\n",
        "\n",
        "Aşağıdaki klasik algoritmalar bir **Pipeline** içinde eğitilecektir:\n",
        "- **Lojistik Regresyon** (baseline)\n",
        "- **Random Forest**\n",
        "- **Decision Tree**\n",
        "- **SGDClassifier** (lineer, `loss='log_loss'`)  \n",
        "- *(Opsiyonel)* **XGBoost** (varsa)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "806959e6",
      "metadata": {
        "id": "806959e6"
      },
      "outputs": [],
      "source": [
        "\n",
        "logreg_pipe = Pipeline([(\"prep\", preprocess),\n",
        "                        (\"clf\", LogisticRegression(max_iter=1000, random_state=RANDOM_STATE))])\n",
        "\n",
        "rf_pipe = Pipeline([(\"prep\", preprocess),\n",
        "                    (\"clf\", RandomForestClassifier(random_state=RANDOM_STATE, n_jobs=-1))])\n",
        "\n",
        "dt_pipe = Pipeline([(\"prep\", preprocess),\n",
        "                    (\"clf\", DecisionTreeClassifier(random_state=RANDOM_STATE))])\n",
        "\n",
        "sgd_pipe = Pipeline([(\"prep\", preprocess),\n",
        "                     (\"clf\", SGDClassifier(loss=\"log_loss\", class_weight=\"balanced\", random_state=RANDOM_STATE))])\n",
        "\n",
        "if XGB_AVAILABLE:\n",
        "    xgb_pipe = Pipeline([(\"prep\", preprocess),\n",
        "                         (\"clf\", XGBClassifier(\n",
        "                             objective=\"binary:logistic\",\n",
        "                             eval_metric=\"logloss\",\n",
        "                             tree_method=\"hist\",\n",
        "                             random_state=RANDOM_STATE,\n",
        "                             n_jobs=-1\n",
        "                         ))])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7651b7bf",
      "metadata": {
        "id": "7651b7bf"
      },
      "source": [
        "\n",
        "## IV. Hiperparametre Optimizasyonu (GridSearchCV)\n",
        "\n",
        "Her model için **ROC-AUC** puanını maksimize edecek şekilde arama yapılır.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "71dbf510",
      "metadata": {
        "id": "71dbf510"
      },
      "outputs": [],
      "source": [
        "\n",
        "search_spaces = {\n",
        "    \"Logistic Regression\": (logreg_pipe, {\n",
        "        \"clf__C\": [0.1, 1.0, 3.0],\n",
        "        \"clf__penalty\": [\"l2\"],\n",
        "        \"clf__solver\": [\"lbfgs\", \"liblinear\"]\n",
        "    }),\n",
        "    \"Random Forest\": (rf_pipe, {\n",
        "        \"clf__n_estimators\": [100, 200],\n",
        "        \"clf__max_depth\": [None, 20, 40],\n",
        "        \"clf__min_samples_split\": [2, 5],\n",
        "        \"clf__min_samples_leaf\": [1, 2]\n",
        "    }),\n",
        "    \"Decision Tree\": (dt_pipe, {\n",
        "        \"clf__max_depth\": [None, 10, 20, 40],\n",
        "        \"clf__min_samples_split\": [2, 5, 10],\n",
        "        \"clf__min_samples_leaf\": [1, 2, 4],\n",
        "        \"clf__class_weight\": [None, \"balanced\"]\n",
        "    }),\n",
        "    \"SGD (Linear)\": (sgd_pipe, {\n",
        "        \"clf__alpha\": [1e-4, 1e-3, 1e-2],\n",
        "        \"clf__max_iter\": [1000, 2000],\n",
        "        \"clf__tol\": [1e-3, 1e-4]\n",
        "    })\n",
        "}\n",
        "\n",
        "if XGB_AVAILABLE:\n",
        "    search_spaces[\"XGBoost\"] = (xgb_pipe, {\n",
        "        \"clf__n_estimators\": [200, 400],\n",
        "        \"clf__max_depth\": [4, 6, 8],\n",
        "        \"clf__learning_rate\": [0.03, 0.1],\n",
        "        \"clf__subsample\": [0.8, 1.0],\n",
        "        \"clf__colsample_bytree\": [0.8, 1.0],\n",
        "        \"clf__scale_pos_weight\": [1.0, scale_pos_weight_val]\n",
        "    })\n",
        "\n",
        "best_models = {}\n",
        "cv_results = []\n",
        "\n",
        "for name, (pipe, grid) in search_spaces.items():\n",
        "    print(f\"\\n>> {name} GridSearch başlıyor...\")\n",
        "    gs = GridSearchCV(\n",
        "        estimator=pipe,\n",
        "        param_grid=grid,\n",
        "        scoring=\"roc_auc\",\n",
        "        cv=3,\n",
        "        n_jobs=-1,\n",
        "        verbose=1\n",
        "    )\n",
        "    gs.fit(X_train, y_train)\n",
        "    best_models[name] = gs.best_estimator_\n",
        "    cv_results.append((name, gs.best_score_, gs.best_params_))\n",
        "    print(f\"{name} en iyi ROC-AUC (CV): {gs.best_score_:.4f}\")\n",
        "    print(f\"{name} en iyi parametreler: {gs.best_params_}\")\n",
        "\n",
        "cv_summary = pd.DataFrame(cv_results, columns=[\"Model\", \"ROC-AUC (CV)\", \"Best Params\"]).sort_values(\"ROC-AUC (CV)\", ascending=False)\n",
        "cv_summary\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4ecaddf1",
      "metadata": {
        "id": "4ecaddf1"
      },
      "source": [
        "\n",
        "## V. Model Değerlendirme\n",
        "\n",
        "Her model için test setinde:\n",
        "- **ROC-AUC**, **PR-AUC**, **F1** skorları\n",
        "- **ROC** ve **Precision-Recall** eğrileri\n",
        "- **Karmaşıklık Matrisi (Confusion Matrix)**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1a26e87c",
      "metadata": {
        "id": "1a26e87c"
      },
      "outputs": [],
      "source": [
        "\n",
        "def evaluate_classifier(name, model, X_tr, y_tr, X_te, y_te):\n",
        "    # Olasılıklar\n",
        "    y_tr_proba = model.predict_proba(X_tr)[:, 1]\n",
        "    y_te_proba = model.predict_proba(X_te)[:, 1]\n",
        "\n",
        "    # 0.5 eşik ile sınıflar\n",
        "    y_tr_pred = (y_tr_proba >= 0.5).astype(int)\n",
        "    y_te_pred = (y_te_proba >= 0.5).astype(int)\n",
        "\n",
        "    # Skorlar\n",
        "    roc_auc_tr = roc_auc_score(y_tr, y_tr_proba)\n",
        "    roc_auc_te = roc_auc_score(y_te, y_te_proba)\n",
        "    ap_tr = average_precision_score(y_tr, y_tr_proba)\n",
        "    ap_te = average_precision_score(y_te, y_te_proba)\n",
        "    f1_tr = f1_score(y_tr, y_tr_pred)\n",
        "    f1_te = f1_score(y_te, y_te_pred)\n",
        "\n",
        "    print(f\"\\n[{name}]\")\n",
        "    print(\"ROC-AUC  (train/test):\", round(roc_auc_tr,4), \"/\", round(roc_auc_te,4))\n",
        "    print(\"PR-AUC   (train/test):\", round(ap_tr,4), \"/\", round(ap_te,4))\n",
        "    print(\"F1-score (train/test):\", round(f1_tr,4), \"/\", round(f1_te,4))\n",
        "    print(\"\\nClassification Report (Test):\\n\", classification_report(y_te, y_te_pred, digits=4))\n",
        "\n",
        "    # Confusion Matrix\n",
        "    cm = confusion_matrix(y_te, y_te_pred)\n",
        "    plt.figure()\n",
        "    plt.imshow(cm, interpolation='nearest')\n",
        "    plt.title(f'Confusion Matrix - {name}')\n",
        "    plt.colorbar()\n",
        "    plt.xticks([0,1], ['Normal (0)', 'Attack (1)'])\n",
        "    plt.yticks([0,1], ['Normal (0)', 'Attack (1)'])\n",
        "    plt.xlabel('Predicted'); plt.ylabel('True')\n",
        "    for i in range(cm.shape[0]):\n",
        "        for j in range(cm.shape[1]):\n",
        "            plt.text(j, i, cm[i, j], ha='center', va='center')\n",
        "    plt.tight_layout(); plt.show()\n",
        "\n",
        "    # ROC\n",
        "    fpr, tpr, _ = roc_curve(y_te, y_te_proba)\n",
        "    plt.figure()\n",
        "    plt.plot(fpr, tpr, label=f'{name}')\n",
        "    plt.plot([0,1],[0,1],'--')\n",
        "    plt.xlabel('False Positive Rate'); plt.ylabel('True Positive Rate')\n",
        "    plt.title(f'ROC Curve - {name}'); plt.legend(); plt.tight_layout(); plt.show()\n",
        "\n",
        "    # PR\n",
        "    prec, rec, _ = precision_recall_curve(y_te, y_te_proba)\n",
        "    plt.figure()\n",
        "    plt.plot(rec, prec, label=f'{name}')\n",
        "    plt.xlabel('Recall'); plt.ylabel('Precision')\n",
        "    plt.title(f'Precision-Recall Curve - {name}'); plt.legend(); plt.tight_layout(); plt.show()\n",
        "\n",
        "for name, model in best_models.items():\n",
        "    evaluate_classifier(name, model, X_train, y_train, X_test, y_test)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1c630e7d",
      "metadata": {
        "id": "1c630e7d"
      },
      "source": [
        "\n",
        "## VI. Özellik Önemi (Random Forest) ve Eşik Ayarı (Opsiyonel)\n",
        "\n",
        "- **Özellik önemi**: En anlamlı değişkenleri görmek için.  \n",
        "- **Eşik ayarı**: İhtiyaca göre **precision/recall** dengesini değiştirmek için.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7ad42c87",
      "metadata": {
        "id": "7ad42c87"
      },
      "outputs": [],
      "source": [
        "\n",
        "# RF bulunursa önemleri çıkar\n",
        "if \"Random Forest\" in best_models:\n",
        "    best_rf = best_models[\"Random Forest\"]\n",
        "    ohe = best_rf.named_steps['prep'].named_transformers_['cat']\n",
        "    cat_feature_names = list(ohe.get_feature_names_out(['protocol_type','service','flag']))\n",
        "    num_feature_names = [c for c in df.columns if c not in ['protocol_type','service','flag','label','label_binary']]\n",
        "    all_feature_names = cat_feature_names + num_feature_names\n",
        "\n",
        "    rf = best_rf.named_steps['clf']\n",
        "    importances = rf.feature_importances_\n",
        "    feat_imp = pd.DataFrame({\"feature\": all_feature_names, \"importance\": importances})\\\n",
        "               .sort_values(\"importance\", ascending=False).head(20)\n",
        "    display(feat_imp)\n",
        "\n",
        "    plt.figure()\n",
        "    plt.barh(feat_imp['feature'][::-1], feat_imp['importance'][::-1])\n",
        "    plt.xlabel(\"Importance\"); plt.title(\"Top 20 Feature Importances (Random Forest)\")\n",
        "    plt.tight_layout(); plt.show()\n",
        "\n",
        "    # Eşik Ayarı (RF)\n",
        "    y_proba = best_rf.predict_proba(X_test)[:, 1]\n",
        "    thresholds = np.linspace(0.1, 0.9, 9)\n",
        "    rows = []\n",
        "    for th in thresholds:\n",
        "        y_pred = (y_proba >= th).astype(int)\n",
        "        tp = ((y_pred == 1) & (y_test == 1)).sum()\n",
        "        fp = ((y_pred == 1) & (y_test == 0)).sum()\n",
        "        fn = ((y_pred == 0) & (y_test == 1)).sum()\n",
        "        precision = tp / (tp + fp) if (tp + fp) > 0 else 0.0\n",
        "        recall = tp / (tp + fn) if (tp + fn) > 0 else 0.0\n",
        "        rows.append({\"threshold\": th, \"precision\": precision, \"recall\": recall, \"f1\": f1_score(y_test, y_pred)})\n",
        "    th_df = pd.DataFrame(rows).sort_values(\"f1\", ascending=False)\n",
        "    display(th_df.head())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dec74811",
      "metadata": {
        "id": "dec74811"
      },
      "source": [
        "\n",
        "## VII. PCA(2D) Üzerinde Sınıf Karar Sınırları (SVM ile)\n",
        "\n",
        "Sunumlarda sınıfları **X–Y düzleminde görmek** için, eğitim/test verisini pipeline sonrası dönüştürüp **PCA(2)** ile indiriyoruz; ardından bir **SVM** ile karar sınırını çiziyoruz.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "04be3a70",
      "metadata": {
        "id": "04be3a70"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Pipeline sonrası dönüştür\n",
        "any_model = list(best_models.values())[0]  # herhangi bir en iyi modelin prep'ini kullan\n",
        "prep = any_model.named_steps['prep']\n",
        "X_train_tr = prep.transform(X_train)\n",
        "X_test_tr  = prep.transform(X_test)\n",
        "\n",
        "# Dense'e çevir (gerekirse)\n",
        "X_train_dense = X_train_tr.toarray() if hasattr(X_train_tr, \"toarray\") else X_train_tr\n",
        "X_test_dense  = X_test_tr.toarray() if hasattr(X_test_tr, \"toarray\") else X_test_tr\n",
        "\n",
        "# PCA(2)\n",
        "pca_vis = PCA(n_components=2, random_state=RANDOM_STATE)\n",
        "X_train_2d = pca_vis.fit_transform(X_train_dense)\n",
        "X_test_2d  = pca_vis.transform(X_test_dense)\n",
        "\n",
        "# Görsel sınırlayıcı model\n",
        "svm_vis = SVC(kernel=\"rbf\", probability=True, random_state=RANDOM_STATE)\n",
        "svm_vis.fit(X_train_2d, y_train)\n",
        "\n",
        "# Meshgrid\n",
        "x1_min, x1_max = X_test_2d[:,0].min()-1, X_test_2d[:,0].max()+1\n",
        "x2_min, x2_max = X_test_2d[:,1].min()-1, X_test_2d[:,1].max()+1\n",
        "xx1, xx2 = np.meshgrid(np.arange(x1_min, x1_max, 0.02),\n",
        "                       np.arange(x2_min, x2_max, 0.02))\n",
        "Z = svm_vis.predict(np.c_[xx1.ravel(), xx2.ravel()]).reshape(xx1.shape)\n",
        "\n",
        "plt.figure(figsize=(7,6))\n",
        "plt.contourf(xx1, xx2, Z, alpha=0.5)\n",
        "plt.scatter(X_test_2d[y_test==0,0], X_test_2d[y_test==0,1], s=20, label=\"Normal (0)\")\n",
        "plt.scatter(X_test_2d[y_test==1,0], X_test_2d[y_test==1,1], s=20, label=\"Attack (1)\")\n",
        "plt.title(\"PCA(2D) Karar Sınırları (SVM-RBF)\")\n",
        "plt.xlabel(\"PC1\"); plt.ylabel(\"PC2\"); plt.legend(); plt.tight_layout(); plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f36c6afe",
      "metadata": {
        "id": "f36c6afe"
      },
      "source": [
        "\n",
        "## VIII. K-Means: Elbow ve Silhouette\n",
        "\n",
        "Denetimsiz öğrenmeye örnek olarak, pipeline sonrası dönüştürülmüş özellikler üzerinde **K-Means** için **Elbow (WCSS)** grafiği ve **Silhouette** skorunu hesaplıyoruz.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f0487903",
      "metadata": {
        "id": "f0487903"
      },
      "outputs": [],
      "source": [
        "\n",
        "X_all = df[categorical_cols + numeric_cols]\n",
        "X_all_tr = prep.transform(X_all)\n",
        "X_all_dense = X_all_tr.toarray() if hasattr(X_all_tr, \"toarray\") else X_all_tr\n",
        "\n",
        "# Elbow (WCSS)\n",
        "wcss = []\n",
        "K = range(2, 11)\n",
        "for k in K:\n",
        "    km = KMeans(n_clusters=k, init=\"k-means++\", n_init=10, random_state=RANDOM_STATE)\n",
        "    km.fit(X_all_dense)\n",
        "    wcss.append(km.inertia_)\n",
        "\n",
        "plt.figure()\n",
        "plt.plot(list(K), wcss, marker=\"o\")\n",
        "plt.title(\"K-Means Elbow (Ön İşlem Sonrası Özellikler)\")\n",
        "plt.xlabel(\"Küme sayısı (k)\"); plt.ylabel(\"WCSS (inertia)\")\n",
        "plt.tight_layout(); plt.show()\n",
        "\n",
        "# Örnek bir k için silhouette\n",
        "k_best = 5  # elbow grafiğine göre güncelleyebilirsiniz\n",
        "km_best = KMeans(n_clusters=k_best, init=\"k-means++\", n_init=10, random_state=RANDOM_STATE)\n",
        "labels = km_best.fit_predict(X_all_dense)\n",
        "print(\"Silhouette skoru:\", round(silhouette_score(X_all_dense, labels), 3))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "94a1888b",
      "metadata": {
        "id": "94a1888b"
      },
      "source": [
        "\n",
        "## IX. SelectKBest (ANOVA F) ile Örnek Özellik Seçimi\n",
        "\n",
        "Karma veri tiplerinde, yalnızca **sayısal** sütunlar üzerinde **ANOVA F (f_classif)** ile en iyi `k` özellik seçimi.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dd3f325e",
      "metadata": {
        "id": "dd3f325e"
      },
      "outputs": [],
      "source": [
        "\n",
        "X_num = df[numeric_cols].copy()\n",
        "y_bin = df[\"label_binary\"].copy()\n",
        "\n",
        "selector = SelectKBest(score_func=f_classif, k=10)  # en iyi 10 sayısal özellik\n",
        "X_num_sel = selector.fit_transform(X_num, y_bin)\n",
        "selected_num_features = np.array(numeric_cols)[selector.get_support()]\n",
        "print(\"Seçilen sayısal özellikler:\", selected_num_features)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4d7a7701",
      "metadata": {
        "id": "4d7a7701"
      },
      "source": [
        "\n",
        "## X. Modellerin Kaydedilmesi\n",
        "\n",
        "En iyi modeller **joblib** ile diske kaydedilir.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "57d9a51e",
      "metadata": {
        "id": "57d9a51e"
      },
      "outputs": [],
      "source": [
        "\n",
        "os.makedirs(\"models\", exist_ok=True)\n",
        "for name, model in best_models.items():\n",
        "    safe = name.lower().replace(\" \", \"_\")\n",
        "    joblib.dump(model, f\"models/{safe}.joblib\")\n",
        "print(\"Modeller kaydedildi: models/ klasöründe.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "22b85d5e",
      "metadata": {
        "id": "22b85d5e"
      },
      "source": [
        "\n",
        "## XI. Kapanış\n",
        "\n",
        "- **Binary (Normal vs Attack)** yaklaşımı ile birden çok klasik algoritma karşılaştırıldı.\n",
        "- **RF** genellikle güçlü sonuç verir; ancak veri yapısına göre diğerleri tercih edilebilir.\n",
        "- **PCA(2)** ile karar sınırı görselleştirme sunumda etkilidir.\n",
        "- **K-Means** ve **SelectKBest** ile denetimsiz öğrenme ve özellik seçimine dair kısa demolar eklendi.\n",
        "- Dengesiz veri için **class_weight**/**scale_pos_weight** gibi yaklaşımlar kritik olabilir.\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}