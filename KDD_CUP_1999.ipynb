{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "df402be3",
   "metadata": {},
   "source": [
    "\n",
    "# KDD Cup 1999 - Anomali Tespiti (Tam Proje) ğŸ‡¹ğŸ‡·\n",
    "\n",
    "Bu defter, KDD Cup 1999 veri seti Ã¼zerinde **anomali (saldÄ±rÄ±) tespiti** iÃ§in uÃ§tan uca bir akÄ±ÅŸ sunar:\n",
    "1. **Veri YÃ¼kleme** (CSV)\n",
    "2. **Ã–n Ä°ÅŸleme** (One-Hot + Standardizasyon, Train/Test)\n",
    "3. **Modeller**: Lojistik Regresyon, Random Forest, Decision Tree, Lineer (SGDClassifier), *(opsiyonel)* XGBoost\n",
    "4. **Hiperparametre Optimizasyonu** (GridSearchCV)\n",
    "5. **DeÄŸerlendirme** (ROC-AUC, PR-EÄŸrisi, F1, Confusion Matrix)\n",
    "6. **PCA(2)** Ã¼zerinde **karar sÄ±nÄ±rÄ±** gÃ¶rselleÅŸtirme (SVM ile)\n",
    "7. **K-Means**: Elbow (WCSS) + **Silhouette** skoru\n",
    "8. **SelectKBest (ANOVA F)** ile Ã¶rnek **Ã¶zellik seÃ§imi**\n",
    "\n",
    "> Not: Bu Ã§alÄ±ÅŸma **sÄ±nÄ±flandÄ±rma** problemidir (Normal vs Attack). Lineer/Multiple Regression (sÃ¼rekli hedef) **kapsam dÄ±ÅŸÄ±dÄ±r**.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8836d859",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import (\n",
    "    roc_auc_score, roc_curve, precision_recall_curve,\n",
    "    average_precision_score, f1_score, confusion_matrix,\n",
    "    classification_report\n",
    ")\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# XGBoost opsiyonel\n",
    "try:\n",
    "    from xgboost import XGBClassifier\n",
    "    XGB_AVAILABLE = True\n",
    "except Exception as e:\n",
    "    XGB_AVAILABLE = False\n",
    "    print(\"XGBoost bulunamadÄ±. Kurmak iÃ§in: pip install xgboost\")\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "\n",
    "import joblib\n",
    "\n",
    "plt.rcParams['figure.figsize'] = (8, 6)\n",
    "RANDOM_STATE = 42\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c13aaeb4",
   "metadata": {},
   "source": [
    "\n",
    "## I. Veri Setinin YÃ¼klenmesi\n",
    "\n",
    "Bu bÃ¶lÃ¼mde **KDD Cup 1999** veri seti `pandas` ile CSV'den okunur.  \n",
    "Etiket sÃ¼tunu (`label`) **ikili** hale getirilir: `normal` â†’ 0, diÄŸer saldÄ±rÄ±lar â†’ 1.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c80b0aee",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# CSV dosya yolu (aynÄ± klasÃ¶re koymanÄ±z Ã¶nerilir)\n",
    "DATA_PATH = \"kdd99_10percent.csv\"  # Ã¶rnek ad\n",
    "\n",
    "# KDD 1999 Ã¶zellik isimleri (41 + label)\n",
    "KDD_COLUMNS = [\n",
    "    \"duration\",\"protocol_type\",\"service\",\"flag\",\"src_bytes\",\"dst_bytes\",\"land\",\n",
    "    \"wrong_fragment\",\"urgent\",\"hot\",\"num_failed_logins\",\"logged_in\",\"num_compromised\",\n",
    "    \"root_shell\",\"su_attempted\",\"num_root\",\"num_file_creations\",\"num_shells\",\n",
    "    \"num_access_files\",\"num_outbound_cmds\",\"is_host_login\",\"is_guest_login\",\n",
    "    \"count\",\"srv_count\",\"serror_rate\",\"srv_serror_rate\",\"rerror_rate\",\"srv_rerror_rate\",\n",
    "    \"same_srv_rate\",\"diff_srv_rate\",\"srv_diff_host_rate\",\"dst_host_count\",\n",
    "    \"dst_host_srv_count\",\"dst_host_same_srv_rate\",\"dst_host_diff_srv_rate\",\n",
    "    \"dst_host_same_src_port_rate\",\"dst_host_srv_diff_host_rate\",\"dst_host_serror_rate\",\n",
    "    \"dst_host_srv_serror_rate\",\"dst_host_rerror_rate\",\"dst_host_srv_rerror_rate\",\n",
    "    \"label\"\n",
    "]\n",
    "\n",
    "if not os.path.exists(DATA_PATH):\n",
    "    raise FileNotFoundError(\n",
    "        f\"Veri dosyasÄ± bulunamadÄ±: {DATA_PATH}\\n\"\n",
    "        \"CSV dosyasÄ±nÄ± klasÃ¶re koyup DATA_PATH'i gÃ¼ncelleyin.\"\n",
    "    )\n",
    "\n",
    "df = pd.read_csv(DATA_PATH, header=None, names=KDD_COLUMNS)\n",
    "\n",
    "# Ä°kili hedef\n",
    "df['label_binary'] = np.where(df['label'].astype(str).str.contains('normal'), 0, 1)\n",
    "\n",
    "print(\"Veri ÅŸekli:\", df.shape)\n",
    "print(\"SaldÄ±rÄ± oranÄ± (1):\", round(df['label_binary'].mean(), 4))\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "538f5262",
   "metadata": {},
   "source": [
    "\n",
    "## II. Veri Ã–n Ä°ÅŸleme\n",
    "\n",
    "- Kategorik: `protocol_type`, `service`, `flag` â†’ **One-Hot Encoding**  \n",
    "- SayÄ±sal: DiÄŸer tÃ¼m sÃ¼tunlar â†’ **StandardScaler**  \n",
    "- **Stratified** train/test bÃ¶lme (sÄ±nÄ±f oranÄ±nÄ± korur)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a38d95fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "categorical_cols = ['protocol_type', 'service', 'flag']\n",
    "numeric_cols = [c for c in df.columns if c not in categorical_cols + ['label', 'label_binary']]\n",
    "\n",
    "X = df[categorical_cols + numeric_cols]\n",
    "y = df['label_binary']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, stratify=y, random_state=RANDOM_STATE\n",
    ")\n",
    "\n",
    "preprocess = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"cat\", OneHotEncoder(handle_unknown=\"ignore\"), categorical_cols),\n",
    "        (\"num\", StandardScaler(with_mean=False), numeric_cols)  # sparse uyumu\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Dengesizlik iÃ§in Ã¶lÃ§ek Ã¶nerisi (XGBoost'ta kullanÄ±lacak)\n",
    "pos = (y_train == 1).sum()\n",
    "neg = (y_train == 0).sum()\n",
    "scale_pos_weight_val = float(neg) / float(pos) if pos > 0 else 1.0\n",
    "print(\"scale_pos_weight Ã¶nerisi:\", round(scale_pos_weight_val, 2))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ee3b212",
   "metadata": {},
   "source": [
    "\n",
    "## III. Modeller\n",
    "\n",
    "AÅŸaÄŸÄ±daki klasik algoritmalar bir **Pipeline** iÃ§inde eÄŸitilecektir:\n",
    "- **Lojistik Regresyon** (baseline)\n",
    "- **Random Forest**\n",
    "- **Decision Tree**\n",
    "- **SGDClassifier** (lineer, `loss='log_loss'`)  \n",
    "- *(Opsiyonel)* **XGBoost** (varsa)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "806959e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "logreg_pipe = Pipeline([(\"prep\", preprocess),\n",
    "                        (\"clf\", LogisticRegression(max_iter=1000, random_state=RANDOM_STATE))])\n",
    "\n",
    "rf_pipe = Pipeline([(\"prep\", preprocess),\n",
    "                    (\"clf\", RandomForestClassifier(random_state=RANDOM_STATE, n_jobs=-1))])\n",
    "\n",
    "dt_pipe = Pipeline([(\"prep\", preprocess),\n",
    "                    (\"clf\", DecisionTreeClassifier(random_state=RANDOM_STATE))])\n",
    "\n",
    "sgd_pipe = Pipeline([(\"prep\", preprocess),\n",
    "                     (\"clf\", SGDClassifier(loss=\"log_loss\", class_weight=\"balanced\", random_state=RANDOM_STATE))])\n",
    "\n",
    "if XGB_AVAILABLE:\n",
    "    xgb_pipe = Pipeline([(\"prep\", preprocess),\n",
    "                         (\"clf\", XGBClassifier(\n",
    "                             objective=\"binary:logistic\",\n",
    "                             eval_metric=\"logloss\",\n",
    "                             tree_method=\"hist\",\n",
    "                             random_state=RANDOM_STATE,\n",
    "                             n_jobs=-1\n",
    "                         ))])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7651b7bf",
   "metadata": {},
   "source": [
    "\n",
    "## IV. Hiperparametre Optimizasyonu (GridSearchCV)\n",
    "\n",
    "Her model iÃ§in **ROC-AUC** puanÄ±nÄ± maksimize edecek ÅŸekilde arama yapÄ±lÄ±r.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71dbf510",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "search_spaces = {\n",
    "    \"Logistic Regression\": (logreg_pipe, {\n",
    "        \"clf__C\": [0.1, 1.0, 3.0],\n",
    "        \"clf__penalty\": [\"l2\"],\n",
    "        \"clf__solver\": [\"lbfgs\", \"liblinear\"]\n",
    "    }),\n",
    "    \"Random Forest\": (rf_pipe, {\n",
    "        \"clf__n_estimators\": [100, 200],\n",
    "        \"clf__max_depth\": [None, 20, 40],\n",
    "        \"clf__min_samples_split\": [2, 5],\n",
    "        \"clf__min_samples_leaf\": [1, 2]\n",
    "    }),\n",
    "    \"Decision Tree\": (dt_pipe, {\n",
    "        \"clf__max_depth\": [None, 10, 20, 40],\n",
    "        \"clf__min_samples_split\": [2, 5, 10],\n",
    "        \"clf__min_samples_leaf\": [1, 2, 4],\n",
    "        \"clf__class_weight\": [None, \"balanced\"]\n",
    "    }),\n",
    "    \"SGD (Linear)\": (sgd_pipe, {\n",
    "        \"clf__alpha\": [1e-4, 1e-3, 1e-2],\n",
    "        \"clf__max_iter\": [1000, 2000],\n",
    "        \"clf__tol\": [1e-3, 1e-4]\n",
    "    })\n",
    "}\n",
    "\n",
    "if XGB_AVAILABLE:\n",
    "    search_spaces[\"XGBoost\"] = (xgb_pipe, {\n",
    "        \"clf__n_estimators\": [200, 400],\n",
    "        \"clf__max_depth\": [4, 6, 8],\n",
    "        \"clf__learning_rate\": [0.03, 0.1],\n",
    "        \"clf__subsample\": [0.8, 1.0],\n",
    "        \"clf__colsample_bytree\": [0.8, 1.0],\n",
    "        \"clf__scale_pos_weight\": [1.0, scale_pos_weight_val]\n",
    "    })\n",
    "\n",
    "best_models = {}\n",
    "cv_results = []\n",
    "\n",
    "for name, (pipe, grid) in search_spaces.items():\n",
    "    print(f\"\\n>> {name} GridSearch baÅŸlÄ±yor...\")\n",
    "    gs = GridSearchCV(\n",
    "        estimator=pipe,\n",
    "        param_grid=grid,\n",
    "        scoring=\"roc_auc\",\n",
    "        cv=3,\n",
    "        n_jobs=-1,\n",
    "        verbose=1\n",
    "    )\n",
    "    gs.fit(X_train, y_train)\n",
    "    best_models[name] = gs.best_estimator_\n",
    "    cv_results.append((name, gs.best_score_, gs.best_params_))\n",
    "    print(f\"{name} en iyi ROC-AUC (CV): {gs.best_score_:.4f}\")\n",
    "    print(f\"{name} en iyi parametreler: {gs.best_params_}\")\n",
    "\n",
    "cv_summary = pd.DataFrame(cv_results, columns=[\"Model\", \"ROC-AUC (CV)\", \"Best Params\"]).sort_values(\"ROC-AUC (CV)\", ascending=False)\n",
    "cv_summary\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ecaddf1",
   "metadata": {},
   "source": [
    "\n",
    "## V. Model DeÄŸerlendirme\n",
    "\n",
    "Her model iÃ§in test setinde:\n",
    "- **ROC-AUC**, **PR-AUC**, **F1** skorlarÄ±\n",
    "- **ROC** ve **Precision-Recall** eÄŸrileri\n",
    "- **KarmaÅŸÄ±klÄ±k Matrisi (Confusion Matrix)**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a26e87c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def evaluate_classifier(name, model, X_tr, y_tr, X_te, y_te):\n",
    "    # OlasÄ±lÄ±klar\n",
    "    y_tr_proba = model.predict_proba(X_tr)[:, 1]\n",
    "    y_te_proba = model.predict_proba(X_te)[:, 1]\n",
    "\n",
    "    # 0.5 eÅŸik ile sÄ±nÄ±flar\n",
    "    y_tr_pred = (y_tr_proba >= 0.5).astype(int)\n",
    "    y_te_pred = (y_te_proba >= 0.5).astype(int)\n",
    "\n",
    "    # Skorlar\n",
    "    roc_auc_tr = roc_auc_score(y_tr, y_tr_proba)\n",
    "    roc_auc_te = roc_auc_score(y_te, y_te_proba)\n",
    "    ap_tr = average_precision_score(y_tr, y_tr_proba)\n",
    "    ap_te = average_precision_score(y_te, y_te_proba)\n",
    "    f1_tr = f1_score(y_tr, y_tr_pred)\n",
    "    f1_te = f1_score(y_te, y_te_pred)\n",
    "\n",
    "    print(f\"\\n[{name}]\")\n",
    "    print(\"ROC-AUC  (train/test):\", round(roc_auc_tr,4), \"/\", round(roc_auc_te,4))\n",
    "    print(\"PR-AUC   (train/test):\", round(ap_tr,4), \"/\", round(ap_te,4))\n",
    "    print(\"F1-score (train/test):\", round(f1_tr,4), \"/\", round(f1_te,4))\n",
    "    print(\"\\nClassification Report (Test):\\n\", classification_report(y_te, y_te_pred, digits=4))\n",
    "\n",
    "    # Confusion Matrix\n",
    "    cm = confusion_matrix(y_te, y_te_pred)\n",
    "    plt.figure()\n",
    "    plt.imshow(cm, interpolation='nearest')\n",
    "    plt.title(f'Confusion Matrix - {name}')\n",
    "    plt.colorbar()\n",
    "    plt.xticks([0,1], ['Normal (0)', 'Attack (1)'])\n",
    "    plt.yticks([0,1], ['Normal (0)', 'Attack (1)'])\n",
    "    plt.xlabel('Predicted'); plt.ylabel('True')\n",
    "    for i in range(cm.shape[0]):\n",
    "        for j in range(cm.shape[1]):\n",
    "            plt.text(j, i, cm[i, j], ha='center', va='center')\n",
    "    plt.tight_layout(); plt.show()\n",
    "\n",
    "    # ROC\n",
    "    fpr, tpr, _ = roc_curve(y_te, y_te_proba)\n",
    "    plt.figure()\n",
    "    plt.plot(fpr, tpr, label=f'{name}')\n",
    "    plt.plot([0,1],[0,1],'--')\n",
    "    plt.xlabel('False Positive Rate'); plt.ylabel('True Positive Rate')\n",
    "    plt.title(f'ROC Curve - {name}'); plt.legend(); plt.tight_layout(); plt.show()\n",
    "\n",
    "    # PR\n",
    "    prec, rec, _ = precision_recall_curve(y_te, y_te_proba)\n",
    "    plt.figure()\n",
    "    plt.plot(rec, prec, label=f'{name}')\n",
    "    plt.xlabel('Recall'); plt.ylabel('Precision')\n",
    "    plt.title(f'Precision-Recall Curve - {name}'); plt.legend(); plt.tight_layout(); plt.show()\n",
    "\n",
    "for name, model in best_models.items():\n",
    "    evaluate_classifier(name, model, X_train, y_train, X_test, y_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c630e7d",
   "metadata": {},
   "source": [
    "\n",
    "## VI. Ã–zellik Ã–nemi (Random Forest) ve EÅŸik AyarÄ± (Opsiyonel)\n",
    "\n",
    "- **Ã–zellik Ã¶nemi**: En anlamlÄ± deÄŸiÅŸkenleri gÃ¶rmek iÃ§in.  \n",
    "- **EÅŸik ayarÄ±**: Ä°htiyaca gÃ¶re **precision/recall** dengesini deÄŸiÅŸtirmek iÃ§in.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ad42c87",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# RF bulunursa Ã¶nemleri Ã§Ä±kar\n",
    "if \"Random Forest\" in best_models:\n",
    "    best_rf = best_models[\"Random Forest\"]\n",
    "    ohe = best_rf.named_steps['prep'].named_transformers_['cat']\n",
    "    cat_feature_names = list(ohe.get_feature_names_out(['protocol_type','service','flag']))\n",
    "    num_feature_names = [c for c in df.columns if c not in ['protocol_type','service','flag','label','label_binary']]\n",
    "    all_feature_names = cat_feature_names + num_feature_names\n",
    "\n",
    "    rf = best_rf.named_steps['clf']\n",
    "    importances = rf.feature_importances_\n",
    "    feat_imp = pd.DataFrame({\"feature\": all_feature_names, \"importance\": importances})\\\n",
    "               .sort_values(\"importance\", ascending=False).head(20)\n",
    "    display(feat_imp)\n",
    "\n",
    "    plt.figure()\n",
    "    plt.barh(feat_imp['feature'][::-1], feat_imp['importance'][::-1])\n",
    "    plt.xlabel(\"Importance\"); plt.title(\"Top 20 Feature Importances (Random Forest)\")\n",
    "    plt.tight_layout(); plt.show()\n",
    "\n",
    "    # EÅŸik AyarÄ± (RF)\n",
    "    y_proba = best_rf.predict_proba(X_test)[:, 1]\n",
    "    thresholds = np.linspace(0.1, 0.9, 9)\n",
    "    rows = []\n",
    "    for th in thresholds:\n",
    "        y_pred = (y_proba >= th).astype(int)\n",
    "        tp = ((y_pred == 1) & (y_test == 1)).sum()\n",
    "        fp = ((y_pred == 1) & (y_test == 0)).sum()\n",
    "        fn = ((y_pred == 0) & (y_test == 1)).sum()\n",
    "        precision = tp / (tp + fp) if (tp + fp) > 0 else 0.0\n",
    "        recall = tp / (tp + fn) if (tp + fn) > 0 else 0.0\n",
    "        rows.append({\"threshold\": th, \"precision\": precision, \"recall\": recall, \"f1\": f1_score(y_test, y_pred)})\n",
    "    th_df = pd.DataFrame(rows).sort_values(\"f1\", ascending=False)\n",
    "    display(th_df.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dec74811",
   "metadata": {},
   "source": [
    "\n",
    "## VII. PCA(2D) Ãœzerinde SÄ±nÄ±f Karar SÄ±nÄ±rlarÄ± (SVM ile)\n",
    "\n",
    "Sunumlarda sÄ±nÄ±flarÄ± **Xâ€“Y dÃ¼zleminde gÃ¶rmek** iÃ§in, eÄŸitim/test verisini pipeline sonrasÄ± dÃ¶nÃ¼ÅŸtÃ¼rÃ¼p **PCA(2)** ile indiriyoruz; ardÄ±ndan bir **SVM** ile karar sÄ±nÄ±rÄ±nÄ± Ã§iziyoruz.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04be3a70",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Pipeline sonrasÄ± dÃ¶nÃ¼ÅŸtÃ¼r\n",
    "any_model = list(best_models.values())[0]  # herhangi bir en iyi modelin prep'ini kullan\n",
    "prep = any_model.named_steps['prep']\n",
    "X_train_tr = prep.transform(X_train)\n",
    "X_test_tr  = prep.transform(X_test)\n",
    "\n",
    "# Dense'e Ã§evir (gerekirse)\n",
    "X_train_dense = X_train_tr.toarray() if hasattr(X_train_tr, \"toarray\") else X_train_tr\n",
    "X_test_dense  = X_test_tr.toarray() if hasattr(X_test_tr, \"toarray\") else X_test_tr\n",
    "\n",
    "# PCA(2)\n",
    "pca_vis = PCA(n_components=2, random_state=RANDOM_STATE)\n",
    "X_train_2d = pca_vis.fit_transform(X_train_dense)\n",
    "X_test_2d  = pca_vis.transform(X_test_dense)\n",
    "\n",
    "# GÃ¶rsel sÄ±nÄ±rlayÄ±cÄ± model\n",
    "svm_vis = SVC(kernel=\"rbf\", probability=True, random_state=RANDOM_STATE)\n",
    "svm_vis.fit(X_train_2d, y_train)\n",
    "\n",
    "# Meshgrid\n",
    "x1_min, x1_max = X_test_2d[:,0].min()-1, X_test_2d[:,0].max()+1\n",
    "x2_min, x2_max = X_test_2d[:,1].min()-1, X_test_2d[:,1].max()+1\n",
    "xx1, xx2 = np.meshgrid(np.arange(x1_min, x1_max, 0.02),\n",
    "                       np.arange(x2_min, x2_max, 0.02))\n",
    "Z = svm_vis.predict(np.c_[xx1.ravel(), xx2.ravel()]).reshape(xx1.shape)\n",
    "\n",
    "plt.figure(figsize=(7,6))\n",
    "plt.contourf(xx1, xx2, Z, alpha=0.5)\n",
    "plt.scatter(X_test_2d[y_test==0,0], X_test_2d[y_test==0,1], s=20, label=\"Normal (0)\")\n",
    "plt.scatter(X_test_2d[y_test==1,0], X_test_2d[y_test==1,1], s=20, label=\"Attack (1)\")\n",
    "plt.title(\"PCA(2D) Karar SÄ±nÄ±rlarÄ± (SVM-RBF)\")\n",
    "plt.xlabel(\"PC1\"); plt.ylabel(\"PC2\"); plt.legend(); plt.tight_layout(); plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f36c6afe",
   "metadata": {},
   "source": [
    "\n",
    "## VIII. K-Means: Elbow ve Silhouette\n",
    "\n",
    "Denetimsiz Ã¶ÄŸrenmeye Ã¶rnek olarak, pipeline sonrasÄ± dÃ¶nÃ¼ÅŸtÃ¼rÃ¼lmÃ¼ÅŸ Ã¶zellikler Ã¼zerinde **K-Means** iÃ§in **Elbow (WCSS)** grafiÄŸi ve **Silhouette** skorunu hesaplÄ±yoruz.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0487903",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X_all = df[categorical_cols + numeric_cols]\n",
    "X_all_tr = prep.transform(X_all)\n",
    "X_all_dense = X_all_tr.toarray() if hasattr(X_all_tr, \"toarray\") else X_all_tr\n",
    "\n",
    "# Elbow (WCSS)\n",
    "wcss = []\n",
    "K = range(2, 11)\n",
    "for k in K:\n",
    "    km = KMeans(n_clusters=k, init=\"k-means++\", n_init=10, random_state=RANDOM_STATE)\n",
    "    km.fit(X_all_dense)\n",
    "    wcss.append(km.inertia_)\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(list(K), wcss, marker=\"o\")\n",
    "plt.title(\"K-Means Elbow (Ã–n Ä°ÅŸlem SonrasÄ± Ã–zellikler)\")\n",
    "plt.xlabel(\"KÃ¼me sayÄ±sÄ± (k)\"); plt.ylabel(\"WCSS (inertia)\")\n",
    "plt.tight_layout(); plt.show()\n",
    "\n",
    "# Ã–rnek bir k iÃ§in silhouette\n",
    "k_best = 5  # elbow grafiÄŸine gÃ¶re gÃ¼ncelleyebilirsiniz\n",
    "km_best = KMeans(n_clusters=k_best, init=\"k-means++\", n_init=10, random_state=RANDOM_STATE)\n",
    "labels = km_best.fit_predict(X_all_dense)\n",
    "print(\"Silhouette skoru:\", round(silhouette_score(X_all_dense, labels), 3))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94a1888b",
   "metadata": {},
   "source": [
    "\n",
    "## IX. SelectKBest (ANOVA F) ile Ã–rnek Ã–zellik SeÃ§imi\n",
    "\n",
    "Karma veri tiplerinde, yalnÄ±zca **sayÄ±sal** sÃ¼tunlar Ã¼zerinde **ANOVA F (f_classif)** ile en iyi `k` Ã¶zellik seÃ§imi.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd3f325e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X_num = df[numeric_cols].copy()\n",
    "y_bin = df[\"label_binary\"].copy()\n",
    "\n",
    "selector = SelectKBest(score_func=f_classif, k=10)  # en iyi 10 sayÄ±sal Ã¶zellik\n",
    "X_num_sel = selector.fit_transform(X_num, y_bin)\n",
    "selected_num_features = np.array(numeric_cols)[selector.get_support()]\n",
    "print(\"SeÃ§ilen sayÄ±sal Ã¶zellikler:\", selected_num_features)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d7a7701",
   "metadata": {},
   "source": [
    "\n",
    "## X. Modellerin Kaydedilmesi\n",
    "\n",
    "En iyi modeller **joblib** ile diske kaydedilir.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57d9a51e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "os.makedirs(\"models\", exist_ok=True)\n",
    "for name, model in best_models.items():\n",
    "    safe = name.lower().replace(\" \", \"_\")\n",
    "    joblib.dump(model, f\"models/{safe}.joblib\")\n",
    "print(\"Modeller kaydedildi: models/ klasÃ¶rÃ¼nde.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22b85d5e",
   "metadata": {},
   "source": [
    "\n",
    "## XI. KapanÄ±ÅŸ\n",
    "\n",
    "- **Binary (Normal vs Attack)** yaklaÅŸÄ±mÄ± ile birden Ã§ok klasik algoritma karÅŸÄ±laÅŸtÄ±rÄ±ldÄ±.\n",
    "- **RF** genellikle gÃ¼Ã§lÃ¼ sonuÃ§ verir; ancak veri yapÄ±sÄ±na gÃ¶re diÄŸerleri tercih edilebilir.\n",
    "- **PCA(2)** ile karar sÄ±nÄ±rÄ± gÃ¶rselleÅŸtirme sunumda etkilidir.\n",
    "- **K-Means** ve **SelectKBest** ile denetimsiz Ã¶ÄŸrenme ve Ã¶zellik seÃ§imine dair kÄ±sa demolar eklendi.\n",
    "- Dengesiz veri iÃ§in **class_weight**/**scale_pos_weight** gibi yaklaÅŸÄ±mlar kritik olabilir.\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
